#!/usr/bin/env python

import sys
import re
import pandas as pd
import numpy as np
from pandas.core.frame import DataFrame
import argparse
from scipy.stats import pearsonr

def parse_arguments(parser):
    parser.add_argument('--pred_file', type=str, help='base-wise mutation rate prediction file generated by MuRaL.')
    parser.add_argument('--window_size', type=int, default=100000, help='window size (bp) for calculating regional rates. Default: 100000.')
    parser.add_argument('--ratio_cutoff', type=float, default=0.2, help='ratio cutoff for filtering windows with few valid sites. Default: 0.2, meaning that windows with  fewer than 0.2*median(numbers of sites in surveyed windows) will be discarded.')
    parser.add_argument('--prob_mut_type_list', type=str, default = ['prob1', 'prob2', 'prob3'], nargs = "+", help="mutation types for calculating correlations. Default: ['prob1', 'prob2', 'prob3']")
    parser.add_argument('--out_prefix', type=str, help='name prefix for output files storing regional mutation rates and correlations')
    args = parser.parse_args()
    return args

def mutation_type(prob_mut_type):
    # choose the observed mutation type to calculate. prob1: A->C/C->A; prob2: A->G/C->G; prob3: A->T/C->T
    probability_mutation_type = {'prob1': 1, 'prob2': 2, 'prob3': 3}
    prob_mut_type_number = probability_mutation_type[prob_mut_type]
    return prob_mut_type_number

def win_cut_cal(table, ratio_cutoff):
    # calculate the cutoff to discard window with insufficient number of sites
    site_count_cutoff = ratio_cutoff*np.median(table['site_count'])
    return site_count_cutoff


def corr_cal(data, window_size, prob_mut_type, output_file, ratio_cutoff):
    window_end = 0 # the boundary of the window
    count = 0 # number of site in each window
    obs = 0 # the observed mutation type 
    obs_total = 0 # total number of observed mutations in the window
    pred_total = 0 # sum of predicted probabilities in the window
    avg_obs = 0 # average observed mutation rate of the window
    avg_pred = 0 # average predicted mutation rate of the window
    win_cutoff = 0 # the cutoff for number of sites to filter windows
    n_sites = len(data) # how many sites for calculation
    end_of_last_window = data.loc[0, 'end']//window_size*window_size+window_size # end of previous window
    last_chromosome = data.loc[0, 'chrom'] # chromosome of previous window
    pre_table = corr_table = pd.DataFrame(columns=('chrom', 'window_end', 'site_count', 'obs_mut', 'avg_obs', 'avg_pred','used_or_deprecated'))

    mut_type_for_calculation = mutation_type(prob_mut_type) # assign the mutation type for calculation
    
    for i in range(n_sites):
        window_end = data.loc[i, 'end']//window_size*window_size+window_size # located window of each site
        chromosome = data.loc[i, 'chrom'] # located chromosome of each site
        if window_end == end_of_last_window and chromosome == last_chromosome:
            # if the site is locateed in current window, add up the observed mutation and predicted probability
            obs = data.loc[i, 'mut_type']
            if obs == mut_type_for_calculation:
                obs_total += 1
            pred_total += data.loc[i, prob_mut_type]
            count += 1
        else:
            # if the site is located in a new window, calculate the average information of last window
            avg_obs = obs_total/count
            avg_pred = pred_total/count
            pre_table = pd.concat([pre_table, 
                                   pd.DataFrame({'chrom':[chromosome], 
                                                 'window_end':[end_of_last_window], 
                                                 'site_count':[count], 
                                                 'obs_mut':[obs_total], 
                                                 'avg_obs':[avg_obs], 
                                                 'avg_pred':[avg_pred]})])
           
            # reset obs, pred, count for calculation of next window
            obs = data.loc[i, 'mut_type']# mut_type for obs
            if obs == mut_type_for_calculation:
                obs_total = 1
            else:
                obs_total = 0
            pred_total = data.loc[i, prob_mut_type]
            count = 1
            # reset window boundary
            end_of_last_window = window_end
            if chromosome != last_chromosome:# new 'if else' 2021.3.26
                last_chromosome = chromosome
                
    # calculate the information of final window
    avg_obs = obs_total/count
    avg_pred = pred_total/count
    pre_table = pd.concat([pre_table, 
                           pd.DataFrame({'chrom':[chromosome], 
                                         'window_end':[end_of_last_window], 
                                         'site_count':[count], 
                                         'obs_mut':[obs_total], 
                                         'avg_obs':[avg_obs], 
                                         'avg_pred':[avg_pred]})], ignore_index=True) # ignore_index is necessary for the use of loc[[i]] 
    
    # filter unqualified windows with < ratio_cutoff*median site_count
    win_cutoff = win_cut_cal(pre_table, ratio_cutoff)
    table_length = len(pre_table)
    for i in range(table_length):
        if pre_table.loc[i, 'site_count'] >= win_cutoff:
            corr_table = pd.concat([corr_table, pre_table.loc[[i]]]) 
            pre_table.loc[i,'used_or_deprecated'] = 'used'
        else:
            pre_table.loc[i,'used_or_deprecated'] = 'deprecated'
    
    # save information of all windows
    pre_table.to_csv(output_file, sep='\t', index=False)

    
    # calculate correlation    
    corr = pearsonr(corr_table['avg_obs'],corr_table['avg_pred']) # pearsonr return [0]: correlation [1]: p-value as a list
    return corr

def main():
    parser = argparse.ArgumentParser(description='regional correlation calculator')
    args = parse_arguments(parser)
    data = pd.read_csv(args.pred_file, sep='\t')
    window_size = int(args.window_size)
    ratio_cutoff = float(args.ratio_cutoff)
    prob_mut_type_list = args.prob_mut_type_list
    for prob_mut_type in prob_mut_type_list:
        window = str(int(window_size/1000)) + 'Kb'
        output_file = str(args.out_prefix) + '.' + window + '.' + prob_mut_type + '.regional_rates.tsv'
        
        correlation = corr_cal(data, window_size, prob_mut_type, output_file, ratio_cutoff)
        corr_file = open(str(args.out_prefix) + '.' + window + '.' + prob_mut_type + '.corr.txt', 'w')
        print(window, prob_mut_type, '%0.4f' % correlation[0], '%e' % correlation[1], sep="\t", file=corr_file)
        corr_file.close()

if __name__ == '__main__':
    main()
